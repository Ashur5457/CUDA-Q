{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WTxVuujNaPFG"
   },
   "source": [
    "# Multi GPU simulations\n",
    "\n",
    "Below we will explore how CUDAQ can seamlessly utilize multiple GPUs and multiple QPUs in the future.\n",
    "\n",
    "1. Scale qubit count to access second and third GPU\n",
    "2. Distribute collection of x_train on multiple GPUs asynchronously\n",
    "3. Distribute collection of terms in a given hamiltonian\n",
    "4. Execute different kernels on different GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "L_0Imw-JaPFI"
   },
   "outputs": [],
   "source": [
    "import cudaq\n",
    "from cudaq import spin\n",
    "import numpy as np\n",
    "\n",
    "# cudaq.set_target('nvidia')\n",
    "# cudaq.set_target('nvidia-mgpu')\n",
    "# cudaq.set_target('qpp-cpu')\n",
    "cudaq.set_target('nvidia-mqpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKiRxOWbaPFI"
   },
   "source": [
    "# Scaling qubit count to go beyond single GPU memory requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_mMD3TdVaPFI",
    "outputId": "1a728c13-4f89-4c60-e3ba-2cc11fb4a521"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU/MIG execution time: 10.56591248512268\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 20\n",
    "n_samples = 1000\n",
    "h = spin.z(0)\n",
    "\n",
    "n_parameters = n_qubits*3\n",
    "parameters = np.random.default_rng(13).uniform(low=0, high=1, size = (n_samples,n_parameters))\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "kernel, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel.qalloc(n_qubits)\n",
    "qubits_list = list(range(n_qubits))\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rx(params[i], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.ry(params[i + n_qubits], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rz(params[i + n_qubits*2], qubits[i])\n",
    "\n",
    "for q1, q2 in zip(qubits_list[0::2], qubits_list[1::2]):\n",
    "    kernel.cz(qubits[q1], qubits[q2])\n",
    "\n",
    "# exp_vals = cudaq.observe_n(kernel, h, parameters)\n",
    "\n",
    "import time\n",
    "t0 = time.time()\n",
    "exp_vals = [cudaq.observe(kernel, h, parameters[i]) for i in range(parameters.shape[0])]\n",
    "print(\"Single GPU/MIG execution time:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uM5Xo1CaPFJ"
   },
   "source": [
    "# Asynchronous data collection via batching x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_4h66U7bkoh",
    "outputId": "12ea80e6-5284-4afa-ba85-cb316879bb24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of GPUs used for distributed QPU simulations: 2\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "num_qpus = str(subprocess.check_output([\"nvidia-smi\", \"-L\"])).count('UUID')\n",
    "print(\"The number of GPUs used for distributed QPU simulations:\", num_qpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsS_IaaCaPFJ",
    "outputId": "5d8b7a8e-0350-4232-b136-6342d9ca915d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 60)\n",
      "2\n",
      "(500, 60)\n"
     ]
    }
   ],
   "source": [
    "print(parameters.shape)\n",
    "\n",
    "xi = np.split(parameters, num_qpus)\n",
    "\n",
    "print(len(xi))\n",
    "\n",
    "print(xi[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bpaNaEqFaPFJ",
    "outputId": "cce6de0d-80a6-4fdd-ac81-9918144ff1fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time using 2 GPUs/MIGs: 5.320219039916992\n"
     ]
    }
   ],
   "source": [
    "asyncresults = []\n",
    "\n",
    "t0 = time.time()\n",
    "for i in range(len(xi)):\n",
    "    for j in range(xi[i].shape[0]):\n",
    "        asyncresults.append(cudaq.observe_async(kernel, h, xi[i][j,:], qpu_id = i))\n",
    "\n",
    "expvals = []\n",
    "for res in asyncresults:\n",
    "    expvals.append(res.get().expectation())\n",
    "print(\"Execution time using\", num_qpus, \"GPUs/MIGs:\", time.time()-t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R2T80iq7aPFJ"
   },
   "source": [
    "# Asynchronous data collection via batching hamiltonian terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czcr9RDHaPFJ",
    "outputId": "3d946220-5e83-4b77-eda6-1a91ce254b79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single GPU/MIG execution time: 0.24846696853637695\n",
      "The expectation value = 0.16\n"
     ]
    }
   ],
   "source": [
    "n_qubits = 10\n",
    "n_terms = 1000\n",
    "\n",
    "# Create a parameterized ansatz kernel\n",
    "kernel, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel.qalloc(n_qubits)\n",
    "qubits_list = list(range(n_qubits))\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rx(params[i], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.ry(params[i + n_qubits], qubits[i])\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel.rz(params[i + n_qubits*2], qubits[i])\n",
    "\n",
    "for q1, q2 in zip(qubits_list[0::2], qubits_list[1::2]):\n",
    "    kernel.cz(qubits[q1], qubits[q2])\n",
    "\n",
    "# We create a random hamiltonian with 10e3 terms\n",
    "hamiltonian = cudaq.SpinOperator.random(n_qubits, n_terms)\n",
    "\n",
    "# Create some random parameters\n",
    "n_parameters = n_qubits*3\n",
    "parameters = np.random.default_rng(13).uniform(low=-1., high=1., size = n_parameters)\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "t0 = time.time()\n",
    "expectation = cudaq.observe(\n",
    "    kernel, hamiltonian, parameters)  # Single GPU.\n",
    "print(\"Single GPU/MIG execution time:\", time.time()-t0)\n",
    "\n",
    "print(\"The expectation value =\", round(expectation.expectation(), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1lf8Ck64aPFJ",
    "outputId": "e2a5d4b9-b658-4e85-d627-1d5a4135950d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time using 2 GPUs/MIGs: 0.11322236061096191\n",
      "The expectation value = 0.16\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "expectation = cudaq.observe(\n",
    "    kernel, hamiltonian, parameters,\n",
    "    execution=cudaq.parallel.thread)  # Single node, multi-GPU.\n",
    "print(\"Execution time using\", num_qpus, \"GPUs/MIGs:\", time.time()-t0)\n",
    "\n",
    "print(\"The expectation value =\", round(expectation.expectation(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9X0VLTS8aPFJ"
   },
   "source": [
    "# Different kernels being executed at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "luv1KwNnaPFJ"
   },
   "outputs": [],
   "source": [
    "cudaq.set_target('nvidia-mqpu')\n",
    "\n",
    "n_qubits = 10\n",
    "n_samples = 500\n",
    "h = spin.z(0)\n",
    "\n",
    "n_parameters = n_qubits\n",
    "parameters = np.random.default_rng(13).uniform(low=0, high=1, size = (n_samples,n_parameters))\n",
    "np.random.seed(1)\n",
    "\n",
    "###################################################\n",
    "\n",
    "kernel1, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel1.qalloc(n_qubits)\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel1.rx(params[i], qubits[i])\n",
    "\n",
    "###################################################\n",
    "\n",
    "kernel2, params = cudaq.make_kernel(list)\n",
    "\n",
    "qubits = kernel2.qalloc(n_qubits)\n",
    "\n",
    "for i in range(n_qubits):\n",
    "    kernel2.ry(params[i], qubits[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "vxj_bdLZaPFJ"
   },
   "outputs": [],
   "source": [
    "exp_vals1 = [cudaq.observe_async(kernel1, h, parameters[i], qpu_id = 0) for i in range(parameters.shape[0])]\n",
    "exp_vals2 = [cudaq.observe_async(kernel2, h, parameters[i], qpu_id = 1) for i in range(parameters.shape[0])]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
